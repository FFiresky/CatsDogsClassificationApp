{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型构建\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import resnet50, ResNet50\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.applications import xception, Xception, resnet50, ResNet50, vgg16, VGG16\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from glob2 import glob\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "\n",
    "def generate_test_prediction(pred, filename):\n",
    "    df = pd.read_csv('prediction/sample_submission.csv')\n",
    "    datagen = image.ImageDataGenerator()\n",
    "    test_generator = datagen.flow_from_directory(\n",
    "                'data/test',\n",
    "                target_size=(224,224),\n",
    "                batch_size=50,\n",
    "                shuffle=False,\n",
    "                class_mode=None)\n",
    "\n",
    "    for i,path in enumerate(test_generator.filenames):\n",
    "        index = int(path[path.rfind('/')+1:path.rfind('.')])\n",
    "        df.set_value(index-1,'label',pred[i])\n",
    "\n",
    "    df.to_csv('./prediction/{}.csv'.format(filename),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型1_Resnet50+重新训练分类器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('gap_resnet50.h5','r') as h:\n",
    "        x_train1 = np.array(h['train'])\n",
    "        y_train1 = np.array(h['label_train'])\n",
    "        x_test1 = np.array(h['test'])\n",
    "\n",
    "x_train1, y_train1 = shuffle(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,360,833\n",
      "Trainable params: 2,360,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 27460 samples, validate on 4847 samples\n",
      "Epoch 1/10\n",
      "27460/27460 [==============================] - 5s 172us/step - loss: 0.0491 - acc: 0.9818 - val_loss: 0.0313 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03128, saving model to ./saved_models/weights.best.model1.hdf5\n",
      "Epoch 2/10\n",
      "27460/27460 [==============================] - 5s 164us/step - loss: 0.0232 - acc: 0.9915 - val_loss: 0.0312 - val_acc: 0.9895\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03128 to 0.03120, saving model to ./saved_models/weights.best.model1.hdf5\n",
      "Epoch 3/10\n",
      "27460/27460 [==============================] - 5s 167us/step - loss: 0.0192 - acc: 0.9929 - val_loss: 0.0309 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03120 to 0.03087, saving model to ./saved_models/weights.best.model1.hdf5\n",
      "Epoch 4/10\n",
      "27460/27460 [==============================] - 4s 164us/step - loss: 0.0130 - acc: 0.9957 - val_loss: 0.0316 - val_acc: 0.9895\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/10\n",
      "27460/27460 [==============================] - 5s 164us/step - loss: 0.0101 - acc: 0.9960 - val_loss: 0.0362 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/10\n",
      "27460/27460 [==============================] - 5s 165us/step - loss: 0.0083 - acc: 0.9969 - val_loss: 0.0453 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/10\n",
      "27460/27460 [==============================] - 4s 164us/step - loss: 0.0082 - acc: 0.9969 - val_loss: 0.0519 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/10\n",
      "27460/27460 [==============================] - 4s 163us/step - loss: 0.0066 - acc: 0.9973 - val_loss: 0.0745 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/10\n",
      "27460/27460 [==============================] - 5s 166us/step - loss: 0.0056 - acc: 0.9978 - val_loss: 0.0771 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/10\n",
      "27460/27460 [==============================] - 4s 163us/step - loss: 0.0044 - acc: 0.9984 - val_loss: 0.0504 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f83a10edf28>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(1024,activation='relu',input_shape=(2048,)))\n",
    "model1.add(Dense(256,activation='relu'))\n",
    "model1.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model1.summary()\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 训练model1\n",
    "checkpointer = ModelCheckpoint(filepath='./saved_models/weights.best.model1.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model1.fit(x_train1,y_train1, epochs=10, batch_size=50, verbose=1, callbacks=[checkpointer], validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/Documents/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:28: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "model1.load_weights(filepath='./saved_models/weights.best.model1.hdf5')\n",
    "\n",
    "model1_pred = model1.predict(x_test1)\n",
    "\n",
    "pred = model1_pred.clip(0.005,0.995)\n",
    "\n",
    "generate_test_prediction(pred, 'model1_base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型2_模型融合+重新训练分类器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2 = []\n",
    "x_test2 = []\n",
    "for filename in ['gap_xception.h5','gap_resnet50.h5','gap_vgg16.h5']:\n",
    "    with h5py.File(filename,'r') as h:\n",
    "        x_train2.append(np.array(h['train']))\n",
    "        y_train2 = np.array(h['label_train'])\n",
    "        x_test2.append(np.array(h['test']))\n",
    "x_train2 = np.concatenate(x_train2, axis=1)\n",
    "x_test2 = np.concatenate(x_test2, axis=1)\n",
    "\n",
    "x_train2, y_train2 = shuffle(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29076 samples, validate on 3231 samples\n",
      "Epoch 1/10\n",
      "29076/29076 [==============================] - 8s 279us/step - loss: 0.0659 - acc: 0.9827 - val_loss: 0.0177 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.01768, saving model to ./saved_models/weights.best.comb_model.hdf5\n",
      "Epoch 2/10\n",
      "29076/29076 [==============================] - 8s 270us/step - loss: 0.0220 - acc: 0.9923 - val_loss: 0.0153 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.01768 to 0.01530, saving model to ./saved_models/weights.best.comb_model.hdf5\n",
      "Epoch 3/10\n",
      "29076/29076 [==============================] - 8s 270us/step - loss: 0.0164 - acc: 0.9940 - val_loss: 0.0127 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01530 to 0.01271, saving model to ./saved_models/weights.best.comb_model.hdf5\n",
      "Epoch 4/10\n",
      "29076/29076 [==============================] - 8s 272us/step - loss: 0.0159 - acc: 0.9944 - val_loss: 0.0119 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01271 to 0.01186, saving model to ./saved_models/weights.best.comb_model.hdf5\n",
      "Epoch 5/10\n",
      "29076/29076 [==============================] - 8s 273us/step - loss: 0.0135 - acc: 0.9956 - val_loss: 0.0071 - val_acc: 0.9975\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01186 to 0.00708, saving model to ./saved_models/weights.best.comb_model.hdf5\n",
      "Epoch 6/10\n",
      "29076/29076 [==============================] - 8s 273us/step - loss: 0.0103 - acc: 0.9960 - val_loss: 0.0084 - val_acc: 0.9972\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/10\n",
      "29076/29076 [==============================] - 8s 273us/step - loss: 0.0094 - acc: 0.9963 - val_loss: 0.0077 - val_acc: 0.9972\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/10\n",
      "29076/29076 [==============================] - 8s 282us/step - loss: 0.0118 - acc: 0.9958 - val_loss: 0.0077 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/10\n",
      "29076/29076 [==============================] - 8s 285us/step - loss: 0.0091 - acc: 0.9966 - val_loss: 0.0093 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/10\n",
      "29076/29076 [==============================] - 8s 265us/step - loss: 0.0089 - acc: 0.9972 - val_loss: 0.0068 - val_acc: 0.9978\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00708 to 0.00676, saving model to ./saved_models/weights.best.comb_model.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f83875c5978>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构造模型\n",
    "model2 = Sequential()\n",
    "model2.add(Dropout(0.5,input_shape=x_train2.shape[1:]))\n",
    "model2.add(Dense(1024,activation='relu'))\n",
    "model2.add(Dense(256,activation='relu'))\n",
    "model2.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./saved_models/weights.best.comb_model.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "model2.fit(x_train2,y_train2, epochs=10, batch_size=50, verbose=1, callbacks=[checkpointer], validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/Documents/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:28: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "model2.load_weights(filepath='./saved_models/weights.best.comb_model.hdf5')\n",
    "\n",
    "model2_pred = model2.predict(x_test2)\n",
    "\n",
    "pred = model2_pred.clip(0.005,0.995)\n",
    "\n",
    "generate_test_prediction(pred, 'model2_base')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
